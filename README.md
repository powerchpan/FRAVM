# FRAVM: Cost-Efficient Fall Risk Assessment with Attention Augmented Vision Machine Learning on Sit-To-Stand Test Videos
Falls among the elderly and other at-risk populations pose a significant public health challenge, necessitating innovative methods to detect and intervene early. While automated fall risk assessment methods using wearable sensors or depth cameras have been proposed, the physical and psychological burden of wearing extra sensors, and the high cost of specialized equipment like Kinect, limits their practical adoption. To tackle this challenge, this work presents a novel machine learning-based fall risk assessment approach called FRAVM, which operates on Five times Sit-To-Stand (FSTS) test videos captured with standard, widely available cameras to identify individuals requiring fall prevention interventions. To enhance the practicality of FRAVM, 3D pose estimation is applied to generate vision-rich 3D body keypoints, mitigating the challenges posed by restricted camera angles. Median-average filtering is used to reduce noise caused by video shaking and pose estimation inaccuracies, while a new Dynamic Time Warping (DTW)-based matching algorithm is designed to handle interference from irrelevant individuals appearing in the video. Furthermore, a novel Attention-augmented Spatial-Temporal Graph Convolutional Network (AST-GCN) is developed for reliably identifying the action in each frame, enabling accurate computation of key kinematic features for fall risk prediction.
